
# nanoGPT-RLHF

A fork from Karpathy's original nano-GPT repo to experiment with fused attention efficiency, finetuning and post-training alignment.

The results are published here ([link](Simplified_Attention___Kernels_are_all_you_need_.pdf)) 

